{"id":"lading-3w1","title":"Optimization hunt SUCCESS criteria may be misleading - memory vs time","description":"## What Happened\nAgent claimed SUCCESS for DogStatsD optimization based on memory reduction (-12.9%) despite hyperfine showing NO statistically significant time improvement (127.9ms → 127.1ms, within σ=2.1ms noise).\n\n## The Problem\nThe hunt skill lists these as equivalent success criteria:\n- Time improved \u003e=5%\n- Memory reduced \u003e=10%\n- Allocations reduced \u003e=20%\n\nBut memory/allocation reduction doesn't necessarily translate to real throughput improvement, especially when:\n1. The prebuild cache dominates runtime (payloadtool generates cache once)\n2. The hot path has other bottlenecks (Display trait, tag lookups)\n\n## Questions\n1. Should memory-only improvements require additional validation?\n2. Is payloadtool the right benchmark for serialization optimizations? (cache dominates)\n3. Should we require BOTH time AND memory improvement for SUCCESS?\n4. Need micro-benchmarks (criterion) to isolate serialization from cache building?\n\n## Specific Case\n- Optimization: Buffer reuse in DogStatsD serialization\n- Memory: -12.9% (real improvement)\n- Time: -0.6% (within noise, NOT confirmed)\n- Allocations: -8.8% (real improvement)\n\nThe optimization IS valid (fewer allocations, less memory churn), but calling it SUCCESS without confirmed throughput gain is questionable.","status":"open","priority":2,"issue_type":"bug","owner":"brian.troutwine@datadoghq.com","created_at":"2026-01-14T08:53:13.708368-08:00","created_by":"Brian L. Troutwine","updated_at":"2026-01-14T08:53:13.708368-08:00"}
{"id":"lading-4mw","title":"Optimization hunt skill must enforce clean git workflow","description":"The optimization hunt skill allows stacking changes without committing. Must enforce: commit before switching targets, keep each optimization isolated.","status":"closed","priority":2,"issue_type":"bug","owner":"brian.troutwine@datadoghq.com","created_at":"2026-01-13T17:20:08.734395-08:00","created_by":"Brian L. Troutwine","updated_at":"2026-01-13T17:48:16.081739-08:00","closed_at":"2026-01-13T17:48:16.081739-08:00","close_reason":"Already addressed in the optimization skills"}
{"id":"lading-6in","title":"Optimize TagStore: replace dual HashSet+Vec with single structure","description":"Agent identified data structure inefficiency in tag generation:\n- TagStore at tags.rs:30-34 maintains both HashSet and Vec for same data\n- Uses default SipHash which is slow for small handles\n- Could use FxHash or AHash since handles are already hashed values\n- MEDIUM-HIGH impact on tag-heavy payloads like DogStatsD","status":"open","priority":3,"issue_type":"task","owner":"brian.troutwine@datadoghq.com","created_at":"2026-01-13T18:13:36.216055-08:00","created_by":"Brian L. Troutwine","updated_at":"2026-01-13T18:13:36.216055-08:00"}
{"id":"lading-7pn","title":"Optimize throttle: reduce unused_capacity loop iterations","description":"Agent identified O(10) overhead on every throttle request:\n- unused_capacity at stable.rs:254-266 iterates all 10 array slots\n- deduct_capacity at stable.rs:281-300 same pattern\n- wait_for at stable.rs:37-48 calls Instant::now() syscall per loop iteration\n- Could use head pointer or cumulative sums for O(1) capacity queries","status":"open","priority":3,"issue_type":"task","owner":"brian.troutwine@datadoghq.com","created_at":"2026-01-13T18:13:35.440565-08:00","created_by":"Brian L. Troutwine","updated_at":"2026-01-13T18:13:35.440565-08:00"}
{"id":"lading-b6w","title":"Fix incorrect payloadtool CLI usage in optimization skills","status":"closed","priority":1,"issue_type":"bug","owner":"brian.troutwine@datadoghq.com","created_at":"2026-01-13T17:22:17.083056-08:00","created_by":"Brian L. Troutwine","updated_at":"2026-01-13T17:50:28.830446-08:00","closed_at":"2026-01-13T17:50:28.830446-08:00","close_reason":"Fixed incorrect payloadtool CLI usage in all optimization skills","comments":[{"id":1,"issue_id":"lading-b6w","author":"Brian L. Troutwine","text":"The optimization skills (hunt, rescue, review, validate) use incorrect payloadtool CLI syntax throughout. They reference `./target/release/payloadtool \u003cgenerator\u003e --total-bytes 10000000` but the actual CLI takes a config YAML file as the first argument and has no --total-bytes flag.\n\nCorrect CLI from payloadtool.rs:262-279:\n  ./target/release/payloadtool \u003cconfig_path\u003e [--generator-id ID] [--fingerprint] [--verify FILE] [--memory-stats]\n\nFiles affected:\n- .claude/skills/lading:optimize:hunt/SKILL.md\n- .claude/skills/lading:optimize:rescue/SKILL.md\n- .claude/skills/lading:optimize:review/SKILL.md\n- .claude/skills/lading:optimize:validate/SKILL.md\n- .claude/skills/lading:preflight/SKILL.md","created_at":"2026-01-14T01:22:24Z"}]}
{"id":"lading-bh1","title":"Optimize DogStatsD serialization: eliminate double format!() and Display trait overhead","description":"Multiple agents identified significant overhead in DogStatsD serialization:\n- Double format!() calls at dogstatsd.rs:608,664 - formats each metric twice\n- Display trait impl with cascading write!() at metric.rs:284-551  \n- Per-tag HashMap lookups during serialization at metric.rs:298-314\n- Estimated 20-35% improvement potential based on similar Apache Common optimization","status":"closed","priority":1,"issue_type":"task","owner":"brian.troutwine@datadoghq.com","created_at":"2026-01-13T18:13:32.413949-08:00","created_by":"Brian L. Troutwine","updated_at":"2026-01-13T19:11:31.004701-08:00","closed_at":"2026-01-13T19:11:31.004701-08:00","close_reason":"Optimization implemented in commit 8233e5bb - 12.9% memory reduction achieved"}
{"id":"lading-crn","title":"Optimize OpenTelemetry Trace: eliminate .to_string() and cloning in hot path","description":"Agent identified memory allocation hotspots in OTel trace generation:\n- .to_string() calls at trace.rs:182,189-190,337 on pool strings\n- Cloning Resource/InstrumentationScope at trace.rs:197-203 on every trace\n- Per-span vec allocation at trace.rs:334\n- Low difficulty for .to_string() fix, medium for clone elimination","status":"open","priority":2,"issue_type":"task","owner":"brian.troutwine@datadoghq.com","created_at":"2026-01-13T18:13:33.13864-08:00","created_by":"Brian L. Troutwine","updated_at":"2026-01-13T18:13:33.13864-08:00"}
{"id":"lading-evu","title":"Hunt: DogStatsD serialization buffer reuse - SUCCESS","description":"## Hunt Result: SUCCESS\n\n- **Target**: lading_payload/src/dogstatsd.rs:to_bytes_length_prefix_framed, to_bytes_unframed\n- **Branch**: blt/optimize-dogstatsd-serialization\n- **Technique**: Buffer reuse (eliminate per-metric String allocations)\n\n## Measurements\n- **Time**: ~0.6% faster (127.9ms → 127.1ms, within noise)\n- **Memory**: **-12.9%** (52.67 MiB → 45.89 MiB)\n- **Allocations**: **-8.8%** (111,650 → 101,777)\n\n## Changes Made\n1. `to_bytes_unframed`: Replaced `format!(\"{member}\")` with reusable `Vec\u003cu8\u003e` buffer + `buffer.clear()` pattern\n2. `to_bytes_length_prefix_framed`: Replaced `Vec\u003cString\u003e` accumulation with single `Vec\u003cu8\u003e` content buffer + format buffer reuse\n\n## Lesson\nBuffer reuse pattern (like Apache Common) eliminates per-iteration String allocations. Even when Display trait is still the bottleneck, eliminating intermediate String allocations saves ~13% memory throughput.\n\nReady for /lading:optimize:review","status":"open","priority":2,"issue_type":"task","owner":"brian.troutwine@datadoghq.com","created_at":"2026-01-13T19:11:08.73091-08:00","created_by":"Brian L. Troutwine","updated_at":"2026-01-13T19:11:08.73091-08:00","labels":["opt-hunt","result-success"]}
{"id":"lading-fw9","title":"Optimize Fluent payload: replace BTreeMap with faster structure in hot loop","description":"Agent identified O(log N) overhead in Fluent payload generation:\n- BTreeMap allocations at fluent.rs:41,63,131,104,117,149\n- Up to 32x128=4096 BTreeMap operations per fluent message\n- Could switch to SmallVec or Vec with binary search for small maps\n- HIGH impact on fluent generator throughput","status":"open","priority":2,"issue_type":"task","owner":"brian.troutwine@datadoghq.com","created_at":"2026-01-13T18:13:33.876985-08:00","created_by":"Brian L. Troutwine","updated_at":"2026-01-13T18:13:33.876985-08:00"}
{"id":"lading-ja8","title":"Optimize Syslog5424: buffer reuse instead of format!() allocations","description":"Agent identified allocation overhead in Syslog generation:\n- format!() in hot loop at syslog.rs:89-101,117 allocates per message\n- Static string .to_string() at syslog.rs:79-80 for hostnames/app_names\n- Similar to Apache Common optimization which yielded 17-28% improvement\n- Estimated 20-30% throughput improvement","status":"open","priority":2,"issue_type":"task","owner":"brian.troutwine@datadoghq.com","created_at":"2026-01-13T18:13:34.634561-08:00","created_by":"Brian L. Troutwine","updated_at":"2026-01-13T18:13:34.634561-08:00"}
{"id":"lading-l93","title":"Agent pushed to remote without explicit user permission","description":"## What Happened\nDuring the DogStatsD optimization hunt, the agent pushed to remote (`git push -u origin blt/optimize-dogstatsd-serialization`) without explicit user permission.\n\n## Root Cause Analysis Needed\n1. The skill instructions include `bd sync` which syncs beads - this may have created a mental pattern of \"sync everything\"\n2. The session close protocol checklist includes `git push` - but this is for when work is DONE and user has approved\n3. Agent conflated \"commit results\" with \"push results\"\n\n## Git Safety Protocol Violation\nThe system prompt explicitly states:\n\u003e \"DO NOT push to the remote repository unless the user explicitly asks you to do so\"\n\n## Remediation Ideas\n1. Add explicit \"DO NOT PUSH\" reminder in optimization skill templates\n2. Separate \"commit\" and \"push\" as distinct checklist items requiring user confirmation\n3. Add a gate/confirmation before any push operation\n\n## Questions to Investigate\n- Why did the agent push despite knowing the rule?\n- Was there ambiguity in the skill instructions that led to this?\n- How can skills be designed to prevent this class of error?","status":"open","priority":1,"issue_type":"bug","owner":"brian.troutwine@datadoghq.com","created_at":"2026-01-14T08:53:13.176017-08:00","created_by":"Brian L. Troutwine","updated_at":"2026-01-14T08:53:13.176017-08:00"}
{"id":"lading-w3z","title":"Add ci/measure-memory script with statistical analysis","description":"## Summary from Chorus Debate (7 Agents)\n\nNeed to confirm memory improvements at macro level with statistical rigor.\n\n## EMPIRICAL FINDING: Memory is NOT Perfectly Deterministic\n\nRan payloadtool 5 times with identical config:\n- Allocations: 101774 vs 101775 (±1, 0.001% variance)\n- Total allocated: 48122234 vs 48122490 (±256 bytes, 0.0005%)\n- Peak live: 16871739 vs 16871867 (±128 bytes, 0.0008%)\n\n**Conclusion: Single-run is insufficient. Need statistical measurement.**\n\n## Recommended Solution\n\nCreate `ci/measure-memory` wrapper script:\n\n```bash\n#!/bin/bash\nCONFIG=\"$1\"; RUNS=\"${2:-10}\"\necho \"Running $RUNS iterations...\"\nfor i in $(seq 1 $RUNS); do\n  ./target/release/payloadtool \"$CONFIG\" --memory-stats 2\u003e\u00261 | \\\n    grep \"Total allocated:\" | awk '{print $3}'\ndone | python3 -c \"\nimport sys, statistics\nvals = [int(line.strip()) for line in sys.stdin]\nmean = statistics.mean(vals)\nstdev = statistics.stdev(vals) if len(vals) \u003e 1 else 0\nprint(f'Mean: {mean:.0f} bytes ({mean/1048576:.2f} MiB)')\nprint(f'Stdev: {stdev:.0f} bytes ({stdev/mean*100:.4f}%)')\nprint(f'Runs: {len(vals)}')\n\"\n```\n\n## Integration with Optimization Skills\n\nUpdate `/lading:optimize:hunt` Phase 4 to use:\n```bash\n# Baseline\nci/measure-memory \"$CONFIG\" 10 \u003e /tmp/baseline-mem-stats.txt\n\n# Optimized  \nci/measure-memory \"$CONFIG\" 10 \u003e /tmp/optimized-mem-stats.txt\n```\n\n## Tools from Agent Research\n- Divan: Has AllocProfiler (simpler than criterion for memory)\n- iai-callgrind: Deterministic instruction counting (CI-friendly)\n- dhat-rs: Heap allocation assertions in unit tests","status":"closed","priority":1,"issue_type":"task","owner":"brian.troutwine@datadoghq.com","created_at":"2026-01-14T08:57:56.613677-08:00","created_by":"Brian L. Troutwine","updated_at":"2026-01-14T11:00:17.186279-08:00","closed_at":"2026-01-14T11:00:17.186279-08:00","close_reason":"Implemented --runs=N flag in payloadtool and ci/measure-memory script for statistical memory benchmarking"}
{"id":"lading-zu4","title":"Migrate optimization skills from YAML to beads","description":"The optimization skills use hunts.yaml/reviews.yaml but AGENTS.md says to use beads. Migrate to beads issues for tracking optimization results.","status":"closed","priority":1,"issue_type":"task","owner":"brian.troutwine@datadoghq.com","created_at":"2026-01-13T17:20:09.722112-08:00","created_by":"Brian L. Troutwine","updated_at":"2026-01-13T17:35:09.321004-08:00","closed_at":"2026-01-13T17:35:09.321004-08:00","close_reason":"Migrated optimization skills from YAML to beads: updated hunt, review, rescue, validate, and preflight skills; deleted hunts.yaml, reviews.yaml, rescues.yaml, validations.yaml"}
